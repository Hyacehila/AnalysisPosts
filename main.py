"""
èˆ†æƒ…åˆ†ææ™ºèƒ½ä½“ - ä¸»å…¥å£æ–‡ä»¶

æœ¬æ–‡ä»¶æ˜¯æ•´ä¸ªç³»ç»Ÿçš„å…¥å£ç‚¹ï¼Œéµå¾ªPocketFlowè®¾è®¡åŸåˆ™ã€‚

================================================================================
ä½¿ç”¨è¯´æ˜
================================================================================

1. å®Œæ•´æµç¨‹è¿è¡Œï¼ˆä¸‰é˜¶æ®µï¼‰ï¼š
   python main.py
   
2. ä»…è¿è¡Œé˜¶æ®µ1ï¼ˆæ•°æ®å¢å¼ºï¼‰ï¼š
   python main.py --stage1-only
   
3. æŒ‡å®šå¤„ç†æ¨¡å¼ï¼š
   python main.py --enhancement-mode async      # å¼‚æ­¥å¹¶è¡Œå¤„ç†
   python main.py --enhancement-mode batch_api  # Batch APIå¤„ç†

4. é…ç½®å¹¶å‘å‚æ•°ï¼š
   python main.py --concurrent 100 --retries 5 --wait 10

================================================================================
"""

import asyncio
import argparse
import concurrent.futures
import time
from typing import Dict, Any

from flow import (
    create_main_flow,
    create_stage1_only_flow,
    create_async_enhancement_flow,
    DEFAULT_CONCURRENT_NUM,
    DEFAULT_MAX_RETRIES,
    DEFAULT_WAIT_TIME,
)


def create_default_shared() -> Dict[str, Any]:
    """
    åˆ›å»ºé»˜è®¤çš„sharedå­—å…¸
    
    æ ¹æ®è®¾è®¡æ–‡æ¡£ï¼Œsharedå­—å…¸åŒ…å«ï¼š
    - dispatcher: è°ƒåº¦æ§åˆ¶é…ç½®
    - config: ä¸‰é˜¶æ®µè·¯å¾„æ§åˆ¶é…ç½®
    - data: æ•°æ®ç®¡ç†
    - results: ç»“æœå­˜å‚¨
    
    Returns:
        Dict: åˆå§‹åŒ–çš„sharedå­—å…¸
    """
    return {
        # === è°ƒåº¦æ§åˆ¶ï¼ˆDispatcherNodeä½¿ç”¨ï¼‰ ===
        "dispatcher": {
            "start_stage": 1,              # èµ·å§‹é˜¶æ®µï¼š1 | 2 | 3
            "run_stages": [1, 2, 3],       # éœ€è¦æ‰§è¡Œçš„é˜¶æ®µåˆ—è¡¨
            "current_stage": 0,            # å½“å‰æ‰§è¡Œåˆ°çš„é˜¶æ®µï¼ˆ0è¡¨ç¤ºæœªå¼€å§‹ï¼‰
            "completed_stages": [],        # å·²å®Œæˆçš„é˜¶æ®µåˆ—è¡¨
            "next_action": None            # ä¸‹ä¸€æ­¥åŠ¨ä½œ
        },
        
        # === ä¸‰é˜¶æ®µè·¯å¾„æ§åˆ¶ ===
        "config": {
            # é˜¶æ®µ1: å¢å¼ºå¤„ç†æ–¹å¼
            "enhancement_mode": "async",   # "async" | "batch_api"
            
            # é˜¶æ®µ2: åˆ†ææ‰§è¡Œæ–¹å¼ï¼ˆå¾…å®ç°ï¼‰
            "analysis_mode": "workflow",   # "workflow" | "agent"
            "tool_source": "local",        # "local" | "mcp"
            
            # é˜¶æ®µ3: æŠ¥å‘Šç”Ÿæˆæ–¹å¼ï¼ˆå¾…å®ç°ï¼‰
            "report_mode": "template",     # "template" | "iterative"
            
            # æ•°æ®æºé…ç½®
            "data_source": {
                "type": "original",
                "enhanced_data_path": "data/enhanced_blogs.json"
            },
            
            # Batch APIé…ç½®
            "batch_api_config": {
                "script_path": "batch/batch_run.py",
                "input_path": "data/beijing_rainstorm_posts.json",
                "output_path": "data/enhanced_blogs.json",
                "wait_for_completion": True
            },
            
            # Agenté…ç½®ï¼ˆå¾…å®ç°ï¼‰
            "agent_config": {
                "max_iterations": 10
            },
            
            # è¿­ä»£æŠ¥å‘Šé…ç½®ï¼ˆå¾…å®ç°ï¼‰
            "iterative_report_config": {
                "max_iterations": 5,
                "min_score_threshold": 80
            }
        },
        
        # === æ•°æ®ç®¡ç† ===
        "data": {
            "blog_data": [],
            "topics_hierarchy": [],
            "sentiment_attributes": [],
            "publisher_objects": [],
            "data_paths": {
                "blog_data_path": "data/beijing_rainstorm_posts.json",
                "topics_path": "data/topics.json",
                "sentiment_attributes_path": "data/sentiment_attributes.json",
                "publisher_objects_path": "data/publisher_objects.json"
            }
        },
        
        # === ç»“æœå­˜å‚¨ ===
        "results": {
            "statistics": {}
        },
        
        # === Agentè¿è¡Œæ—¶çŠ¶æ€ï¼ˆå¾…å®ç°ï¼‰ ===
        "agent": {
            "available_tools": [],
            "execution_history": [],
            "current_iteration": 0,
            "max_iterations": 10,
            "is_finished": False
        },
        
        # === æŠ¥å‘Šç”ŸæˆçŠ¶æ€ï¼ˆå¾…å®ç°ï¼‰ ===
        "report": {
            "iteration": 0,
            "current_draft": "",
            "revision_feedback": "",
            "review_history": []
        }
    }


async def run_main_flow_async(
    shared: Dict[str, Any],
    concurrent_num: int = DEFAULT_CONCURRENT_NUM,
    max_retries: int = DEFAULT_MAX_RETRIES,
    wait_time: int = DEFAULT_WAIT_TIME
) -> Dict[str, Any]:
    """
    å¼‚æ­¥è¿è¡Œä¸»Flow
    
    Args:
        shared: å…±äº«æ•°æ®å­—å…¸
        concurrent_num: æœ€å¤§å¹¶å‘æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        wait_time: é‡è¯•ç­‰å¾…æ—¶é—´
    
    Returns:
        Dict: æ‰§è¡Œåçš„sharedå­—å…¸
    """
    # è®¾ç½®çº¿ç¨‹æ± ï¼ˆç”¨äºå¼‚æ­¥è°ƒç”¨åŒæ­¥LLMå‡½æ•°ï¼‰
    thread_pool_size = concurrent_num + 20
    executor = concurrent.futures.ThreadPoolExecutor(max_workers=thread_pool_size)
    loop = asyncio.get_running_loop()
    loop.set_default_executor(executor)
    
    print(f"\n[Main] çº¿ç¨‹æ± é…ç½®: max_workers={thread_pool_size}")
    
    # åˆ›å»ºä¸»Flow
    main_flow = create_main_flow(
        concurrent_num=concurrent_num,
        max_retries=max_retries,
        wait_time=wait_time
    )
    
    # è¿è¡ŒFlow
    await main_flow.run_async(shared)
    
    return shared


async def run_stage1_only_async(
    shared: Dict[str, Any],
    mode: str = "async",
    concurrent_num: int = DEFAULT_CONCURRENT_NUM,
    max_retries: int = DEFAULT_MAX_RETRIES,
    wait_time: int = DEFAULT_WAIT_TIME
) -> Dict[str, Any]:
    """
    å¼‚æ­¥è¿è¡Œä»…é˜¶æ®µ1çš„Flow
    
    Args:
        shared: å…±äº«æ•°æ®å­—å…¸
        mode: å¤„ç†æ¨¡å¼ï¼Œ"async" æˆ– "batch_api"
        concurrent_num: æœ€å¤§å¹¶å‘æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        wait_time: é‡è¯•ç­‰å¾…æ—¶é—´
    
    Returns:
        Dict: æ‰§è¡Œåçš„sharedå­—å…¸
    """
    # è®¾ç½®å¤„ç†æ¨¡å¼
    shared["config"]["enhancement_mode"] = mode
    
    if mode == "async":
        # è®¾ç½®çº¿ç¨‹æ± 
        thread_pool_size = concurrent_num + 20
        executor = concurrent.futures.ThreadPoolExecutor(max_workers=thread_pool_size)
        loop = asyncio.get_running_loop()
        loop.set_default_executor(executor)
        
        print(f"\n[Main] çº¿ç¨‹æ± é…ç½®: max_workers={thread_pool_size}")
    
    # åˆ›å»ºé˜¶æ®µ1 Flow
    stage1_flow = create_stage1_only_flow(
        mode=mode,
        concurrent_num=concurrent_num,
        max_retries=max_retries,
        wait_time=wait_time
    )
    
    # è¿è¡ŒFlow
    await stage1_flow.run_async(shared)
    
    return shared


def print_banner():
    """æ‰“å°ç¨‹åºå¯åŠ¨æ¨ªå¹…"""
    print("\n" + "=" * 60)
    print("èˆ†æƒ…åˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿ".center(56))
    print("=" * 60)
    print("åŸºäºPocketFlowæ¡†æ¶ | ä¸‰é˜¶æ®µè§£è€¦æ¶æ„")
    print("=" * 60 + "\n")


def print_config(shared: Dict[str, Any], args: argparse.Namespace):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("é…ç½®ä¿¡æ¯:")
    print(f"  â”œâ”€ èµ·å§‹é˜¶æ®µ: {shared['dispatcher']['start_stage']}")
    print(f"  â”œâ”€ æ‰§è¡Œé˜¶æ®µ: {shared['dispatcher']['run_stages']}")
    print(f"  â”œâ”€ å¢å¼ºæ¨¡å¼: {shared['config']['enhancement_mode']}")
    print(f"  â”œâ”€ åˆ†ææ¨¡å¼: {shared['config']['analysis_mode']}")
    print(f"  â”œâ”€ æŠ¥å‘Šæ¨¡å¼: {shared['config']['report_mode']}")
    print(f"  â”œâ”€ è¾“å…¥è·¯å¾„: {args.data_path}")
    print(f"  â”œâ”€ è¾“å‡ºè·¯å¾„: {args.output_path}")
    print(f"  â”œâ”€ å¹¶å‘æ•°: {args.concurrent}")
    print(f"  â”œâ”€ é‡è¯•æ¬¡æ•°: {args.retries}")
    print(f"  â””â”€ é‡è¯•ç­‰å¾…: {args.wait}ç§’")
    print()


def print_results(shared: Dict[str, Any], elapsed_time: float):
    """æ‰“å°æ‰§è¡Œç»“æœ"""
    print("\n" + "=" * 60)
    print("æ‰§è¡Œç»“æœ".center(56))
    print("=" * 60)
    
    # å®Œæˆçš„é˜¶æ®µ
    completed_stages = shared.get("dispatcher", {}).get("completed_stages", [])
    print(f"\nå·²å®Œæˆé˜¶æ®µ: {completed_stages}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = shared.get("results", {}).get("statistics", {})
    if stats:
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  â”œâ”€ æ€»åšæ–‡æ•°: {stats.get('total_blogs', 0)}")
        print(f"  â””â”€ å·²å¤„ç†æ•°: {stats.get('processed_blogs', 0)}")
        
        # ç©ºå­—æ®µç»Ÿè®¡
        empty_fields = stats.get("empty_fields", {})
        if empty_fields:
            print(f"\nâš ï¸  ç©ºå­—æ®µç»Ÿè®¡:")
            print(f"  â”œâ”€ æƒ…æ„Ÿææ€§ä¸ºç©º: {empty_fields.get('sentiment_polarity_empty', 0)}")
            print(f"  â”œâ”€ æƒ…æ„Ÿå±æ€§ä¸ºç©º: {empty_fields.get('sentiment_attribute_empty', 0)}")
            print(f"  â”œâ”€ ä¸»é¢˜ä¸ºç©º: {empty_fields.get('topics_empty', 0)}")
            print(f"  â””â”€ å‘å¸ƒè€…ä¸ºç©º: {empty_fields.get('publisher_empty', 0)}")
    
    # ä¿å­˜çŠ¶æ€
    data_save = shared.get("results", {}).get("data_save", {})
    if data_save.get("saved"):
        print(f"\nğŸ’¾ æ•°æ®ä¿å­˜:")
        print(f"  â”œâ”€ ä¿å­˜è·¯å¾„: {data_save.get('output_path', 'N/A')}")
        print(f"  â””â”€ ä¿å­˜æ•°é‡: {data_save.get('data_count', 0)} æ¡")
    
    # æ—¶é—´ç»Ÿè®¡
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    
    processed_blogs = stats.get('processed_blogs', 0)
    if processed_blogs > 0:
        throughput = processed_blogs / elapsed_time
        print(f"ğŸ“ˆ å¤„ç†æ•ˆç‡: {throughput:.2f} æ¡/ç§’")
    
    print("\n" + "=" * 60 + "\n")


async def main_async(args: argparse.Namespace):
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    print_banner()
    
    # åˆ›å»ºsharedå­—å…¸
    shared = create_default_shared()
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    shared["config"]["enhancement_mode"] = args.enhancement_mode
    
    # æ›´æ–°æ•°æ®è·¯å¾„é…ç½®
    shared["data"]["data_paths"]["blog_data_path"] = args.data_path
    shared["config"]["data_source"]["enhanced_data_path"] = args.output_path
    shared["config"]["batch_api_config"]["input_path"] = args.data_path
    shared["config"]["batch_api_config"]["output_path"] = args.output_path
    
    if args.stage1_only:
        # ä»…è¿è¡Œé˜¶æ®µ1
        shared["dispatcher"]["run_stages"] = [1]
        print("[Main] æ¨¡å¼: ä»…è¿è¡Œé˜¶æ®µ1ï¼ˆæ•°æ®å¢å¼ºï¼‰\n")
    else:
        # å®Œæ•´æµç¨‹ï¼ˆç›®å‰åªæœ‰é˜¶æ®µ1å¯ç”¨ï¼‰
        # TODO: é˜¶æ®µ2å’Œé˜¶æ®µ3å®ç°åï¼Œå–æ¶ˆæ­¤é™åˆ¶
        shared["dispatcher"]["run_stages"] = [1]
        print("[Main] æ¨¡å¼: å®Œæ•´æµç¨‹ï¼ˆç›®å‰ä»…é˜¶æ®µ1å¯ç”¨ï¼‰\n")
    
    # æ‰“å°é…ç½®
    print_config(shared, args)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\n")
    
    try:
        if args.stage1_only:
            await run_stage1_only_async(
                shared=shared,
                mode=args.enhancement_mode,
                concurrent_num=args.concurrent,
                max_retries=args.retries,
                wait_time=args.wait
            )
        else:
            await run_main_flow_async(
                shared=shared,
                concurrent_num=args.concurrent,
                max_retries=args.retries,
                wait_time=args.wait
            )
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # æ‰“å°ç»“æœ
        print_results(shared, elapsed_time)
        
    except Exception as e:
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {str(e)}")
        print(f"â±ï¸  è¿è¡Œæ—¶é—´: {elapsed_time:.2f} ç§’")
        
        import traceback
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°å…¥å£"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="èˆ†æƒ…åˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python main.py                          # è¿è¡Œå®Œæ•´æµç¨‹
  python main.py --stage1-only            # ä»…è¿è¡Œé˜¶æ®µ1
  python main.py --enhancement-mode async # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
  python main.py --concurrent 100         # è®¾ç½®å¹¶å‘æ•°ä¸º100
        """
    )
    
    parser.add_argument(
        "--stage1-only",
        action="store_true",
        help="ä»…è¿è¡Œé˜¶æ®µ1ï¼ˆæ•°æ®å¢å¼ºï¼‰"
    )
    
    parser.add_argument(
        "--enhancement-mode",
        choices=["async", "batch_api"],
        default="async",
        help="é˜¶æ®µ1å¤„ç†æ¨¡å¼: asyncï¼ˆå¼‚æ­¥å¹¶è¡Œï¼‰æˆ– batch_apiï¼ˆBatch APIï¼‰"
    )
    
    parser.add_argument(
        "--concurrent",
        type=int,
        default=DEFAULT_CONCURRENT_NUM,
        help=f"æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤: {DEFAULT_CONCURRENT_NUM}ï¼‰"
    )
    
    parser.add_argument(
        "--retries",
        type=int,
        default=DEFAULT_MAX_RETRIES,
        help=f"æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤: {DEFAULT_MAX_RETRIES}ï¼‰"
    )
    
    parser.add_argument(
        "--wait",
        type=int,
        default=DEFAULT_WAIT_TIME,
        help=f"é‡è¯•ç­‰å¾…æ—¶é—´/ç§’ï¼ˆé»˜è®¤: {DEFAULT_WAIT_TIME}ï¼‰"
    )
    
    parser.add_argument(
        "--data-path",
        type=str,
        default="data/beijing_rainstorm_posts.json",
        help="è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--output-path",
        type=str,
        default="data/enhanced_blogs.json",
        help="è¾“å‡ºæ•°æ®æ–‡ä»¶è·¯å¾„"
    )
    
    args = parser.parse_args()
    
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main_async(args))


if __name__ == "__main__":
    # =========================================================================
    # å¿«é€Ÿé…ç½®åŒºåŸŸ - ä¿®æ”¹ä»¥ä¸‹å‚æ•°å¯å¿«é€Ÿè°ƒæ•´è¿è¡Œé…ç½®
    # =========================================================================
    
    # æ˜¯å¦ä½¿ç”¨å¿«é€Ÿé…ç½®ï¼ˆTrue: ä½¿ç”¨ä¸‹æ–¹é…ç½®ï¼ŒFalse: ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼‰
    USE_QUICK_CONFIG = True
    
    if USE_QUICK_CONFIG:
        # ----- å¸¸ç”¨é…ç½®å‚æ•° -----
        
        # æ•°æ®è·¯å¾„é…ç½®
        INPUT_DATA_PATH = "data/test_posts.json"           # è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„
        OUTPUT_DATA_PATH = "data/test_enhanced_blogs.json" # è¾“å‡ºå¢å¼ºæ•°æ®è·¯å¾„
        
        # è¿è¡Œæ¨¡å¼é…ç½®
        STAGE1_ONLY = True                  # True: ä»…è¿è¡Œé˜¶æ®µ1, False: è¿è¡Œå…¨éƒ¨é˜¶æ®µ
        ENHANCEMENT_MODE = "async"          # "async": å¼‚æ­¥å¹¶è¡Œ, "batch_api": Batch API
        
        # æ€§èƒ½é…ç½®
        CONCURRENT_NUM = 60                 # æœ€å¤§å¹¶å‘æ•°
        MAX_RETRIES = 3                     # æœ€å¤§é‡è¯•æ¬¡æ•°
        WAIT_TIME = 8                       # é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        # ----- æ„å»ºå‚æ•° -----
        import sys
        sys.argv = [
            "main.py",
            "--data-path", INPUT_DATA_PATH,
            "--output-path", OUTPUT_DATA_PATH,
            "--enhancement-mode", ENHANCEMENT_MODE,
            "--concurrent", str(CONCURRENT_NUM),
            "--retries", str(MAX_RETRIES),
            "--wait", str(WAIT_TIME),
        ]
        if STAGE1_ONLY:
            sys.argv.append("--stage1-only")
    
    # è¿è¡Œä¸»å‡½æ•°
    main()
