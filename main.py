"""
èˆ†æƒ…åˆ†ææ™ºèƒ½ä½“ - ä¸»å…¥å£æ–‡ä»¶

ç³»ç»Ÿé‡‡ç”¨ä¸­å¤®è°ƒåº¦æ¨¡å¼ï¼Œåªéœ€é…ç½®sharedå­—å…¸å¹¶å¯åŠ¨ä¸»Flowå³å¯ã€‚
DispatcherNodeä¼šæ ¹æ®é…ç½®è‡ªåŠ¨åœ¨å„èŠ‚ç‚¹é—´æµè½¬ã€‚

================================================================================
ä½¿ç”¨è¯´æ˜
================================================================================

1. åœ¨main()å‡½æ•°çš„é…ç½®åŒºåŸŸä¿®æ”¹å‚æ•°
2. è¿è¡Œ python main.py å¯åŠ¨ç³»ç»Ÿ
3. ç³»ç»Ÿä¼šè‡ªåŠ¨æ ¹æ®run_stagesé…ç½®æ‰§è¡Œå¯¹åº”é˜¶æ®µ

================================================================================
"""

import asyncio
import concurrent.futures
import time
from typing import Dict, Any, List

from flow import create_main_flow


def init_shared(
    # æ•°æ®è·¯å¾„é…ç½®
    input_data_path: str = "data/beijing_rainstorm_posts.json",
    output_data_path: str = "data/enhanced_blogs.json",
    topics_path: str = "data/topics.json",
    sentiment_attributes_path: str = "data/sentiment_attributes.json",
    publisher_objects_path: str = "data/publisher_objects.json",
    # è°ƒåº¦é…ç½®
    start_stage: int = 1,
    run_stages: List[int] = None,
    # é˜¶æ®µ1é…ç½®
    enhancement_mode: str = "async",
    # é˜¶æ®µ2é…ç½®
    analysis_mode: str = "workflow",
    tool_source: str = "local",
    agent_max_iterations: int = 10,
    # é˜¶æ®µ3é…ç½®
    report_mode: str = "template",
    report_max_iterations: int = 5,
    report_min_score: int = 80,
    # Batch APIé…ç½®
    batch_script_path: str = "batch/batch_run.py",
) -> Dict[str, Any]:
    """
    åˆå§‹åŒ–sharedå­—å…¸
    
    sharedå­—å…¸æ˜¯èŠ‚ç‚¹é—´é€šä¿¡çš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼ŒåŒ…å«æ‰€æœ‰é…ç½®å’Œè¿è¡Œæ—¶çŠ¶æ€ã€‚
    DispatcherNodeä¼šæ ¹æ®æ­¤é…ç½®å†³å®šæ‰§è¡Œè·¯å¾„ã€‚
    
    Args:
        input_data_path: è¾“å…¥åšæ–‡æ•°æ®æ–‡ä»¶è·¯å¾„
        output_data_path: è¾“å‡ºå¢å¼ºæ•°æ®æ–‡ä»¶è·¯å¾„
        topics_path: ä¸»é¢˜å±‚æ¬¡ç»“æ„æ–‡ä»¶è·¯å¾„
        sentiment_attributes_path: æƒ…æ„Ÿå±æ€§åˆ—è¡¨æ–‡ä»¶è·¯å¾„
        publisher_objects_path: å‘å¸ƒè€…ç±»å‹åˆ—è¡¨æ–‡ä»¶è·¯å¾„
        start_stage: èµ·å§‹é˜¶æ®µ (1/2/3)
        run_stages: éœ€è¦æ‰§è¡Œçš„é˜¶æ®µåˆ—è¡¨ï¼Œé»˜è®¤[1]ï¼ˆç›®å‰ä»…é˜¶æ®µ1å¯ç”¨ï¼‰
        enhancement_mode: é˜¶æ®µ1å¤„ç†æ¨¡å¼ ("async" | "batch_api")
        analysis_mode: é˜¶æ®µ2åˆ†ææ¨¡å¼ ("workflow" | "agent")
        tool_source: Agentå·¥å…·æ¥æº ("local" | "mcp")
        agent_max_iterations: Agentæœ€å¤§è¿­ä»£æ¬¡æ•°
        report_mode: é˜¶æ®µ3æŠ¥å‘Šæ¨¡å¼ ("template" | "iterative")
        report_max_iterations: æŠ¥å‘Šæœ€å¤§è¿­ä»£æ¬¡æ•°
        report_min_score: æŠ¥å‘Šæ»¡æ„åº¦é˜ˆå€¼
        batch_script_path: Batch APIè„šæœ¬è·¯å¾„
    
    Returns:
        Dict: åˆå§‹åŒ–å®Œæˆçš„sharedå­—å…¸
    """
    if run_stages is None:
        run_stages = [1]  # ç›®å‰ä»…é˜¶æ®µ1å¯ç”¨
    
    return {
        # === è°ƒåº¦æ§åˆ¶ï¼ˆDispatcherNodeä½¿ç”¨ï¼‰ ===
        "dispatcher": {
            "start_stage": start_stage,
            "run_stages": run_stages,
            "current_stage": 0,
            "completed_stages": [],
            "next_action": None
        },
        
        # === ä¸‰é˜¶æ®µè·¯å¾„æ§åˆ¶ ===
        "config": {
            "enhancement_mode": enhancement_mode,
            "analysis_mode": analysis_mode,
            "tool_source": tool_source,
            "report_mode": report_mode,
            "data_source": {
                "type": "original",
                "enhanced_data_path": output_data_path
            },
            "batch_api_config": {
                "script_path": batch_script_path,
                "input_path": input_data_path,
                "output_path": output_data_path,
                "wait_for_completion": True
            },
            "agent_config": {
                "max_iterations": agent_max_iterations
            },
            "iterative_report_config": {
                "max_iterations": report_max_iterations,
                "min_score_threshold": report_min_score
            }
        },
        
        # === æ•°æ®ç®¡ç† ===
        "data": {
            "blog_data": [],
            "topics_hierarchy": [],
            "sentiment_attributes": [],
            "publisher_objects": [],
            "load_type": "original",
            "data_paths": {
                "blog_data_path": input_data_path,
                "topics_path": topics_path,
                "sentiment_attributes_path": sentiment_attributes_path,
                "publisher_objects_path": publisher_objects_path
            }
        },
        
        # === ç»“æœå­˜å‚¨ ===
        "results": {
            "statistics": {},
            "data_save": {},
            "batch_api": {}
        },
        
        # === Agentè¿è¡Œæ—¶çŠ¶æ€ ===
        "agent": {
            "available_tools": [],
            "execution_history": [],
            "current_iteration": 0,
            "max_iterations": agent_max_iterations,
            "is_finished": False
        },
        
        # === æŠ¥å‘Šç”ŸæˆçŠ¶æ€ ===
        "report": {
            "iteration": 0,
            "current_draft": "",
            "revision_feedback": "",
            "review_history": [],
            "template": "",
            "sections": {}
        },
        
        # === æœ€ç»ˆè¾“å‡º ===
        "final_summary": {}
    }


def print_banner():
    """æ‰“å°ç¨‹åºå¯åŠ¨æ¨ªå¹…"""
    print("\n" + "=" * 60)
    print("èˆ†æƒ…åˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿ".center(56))
    print("=" * 60)
    print("åŸºäºPocketFlowæ¡†æ¶ | ä¸­å¤®è°ƒåº¦æ¨¡å¼")
    print("=" * 60 + "\n")


def print_config(shared: Dict[str, Any], concurrent_num: int, max_retries: int, wait_time: int):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("é…ç½®ä¿¡æ¯:")
    print(f"  â”œâ”€ æ‰§è¡Œé˜¶æ®µ: {shared['dispatcher']['run_stages']}")
    print(f"  â”œâ”€ å¢å¼ºæ¨¡å¼: {shared['config']['enhancement_mode']}")
    print(f"  â”œâ”€ åˆ†ææ¨¡å¼: {shared['config']['analysis_mode']}")
    print(f"  â”œâ”€ æŠ¥å‘Šæ¨¡å¼: {shared['config']['report_mode']}")
    print(f"  â”œâ”€ è¾“å…¥è·¯å¾„: {shared['data']['data_paths']['blog_data_path']}")
    print(f"  â”œâ”€ è¾“å‡ºè·¯å¾„: {shared['config']['data_source']['enhanced_data_path']}")
    print(f"  â”œâ”€ å¹¶å‘æ•°: {concurrent_num}")
    print(f"  â”œâ”€ é‡è¯•æ¬¡æ•°: {max_retries}")
    print(f"  â””â”€ é‡è¯•ç­‰å¾…: {wait_time}ç§’")
    print()


def print_results(shared: Dict[str, Any], elapsed_time: float):
    """
    æ‰“å°æœ€ç»ˆæ‰§è¡Œæ‘˜è¦
    
    æ³¨æ„ï¼šè¯¦ç»†çš„æ•°æ®ç»Ÿè®¡ä¿¡æ¯å·²ç”± DataValidationAndOverviewNode åœ¨é˜¶æ®µ1å®Œæˆæ—¶æ‰“å°ï¼Œ
    æ­¤å‡½æ•°ä»…æ‰“å°æœ€ç»ˆæ‘˜è¦ä¿¡æ¯ï¼ˆè€—æ—¶ã€æ•ˆç‡ã€ä¿å­˜çŠ¶æ€ï¼‰
    """
    print("\n" + "=" * 60)
    print("æ‰§è¡Œæ‘˜è¦".center(56))
    print("=" * 60)
    
    completed_stages = shared.get("dispatcher", {}).get("completed_stages", [])
    print(f"\nâœ… å·²å®Œæˆé˜¶æ®µ: {completed_stages}")
    
    # æ•°æ®ä¿å­˜çŠ¶æ€ï¼ˆé˜¶æ®µ1ç»“æœï¼‰
    data_save = shared.get("stage1_results", {}).get("data_save", {})
    if data_save.get("saved"):
        print(f"\nğŸ’¾ æ•°æ®ä¿å­˜:")
        print(f"  â”œâ”€ ä¿å­˜è·¯å¾„: {data_save.get('output_path', 'N/A')}")
        print(f"  â””â”€ ä¿å­˜æ•°é‡: {data_save.get('data_count', 0)} æ¡")
    
    # è€—æ—¶å’Œæ•ˆç‡
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    
    stats = shared.get("stage1_results", {}).get("statistics", {})
    processed_blogs = stats.get('processed_blogs', 0)
    if processed_blogs > 0 and elapsed_time > 0:
        print(f"ğŸ“ˆ å¤„ç†æ•ˆç‡: {processed_blogs / elapsed_time:.2f} æ¡/ç§’")
    
    print("\n" + "=" * 60 + "\n")


async def run(
    shared: Dict[str, Any],
    concurrent_num: int = 60,
    max_retries: int = 3,
    wait_time: int = 8
):
    """
    è¿è¡Œä¸»Flow - ç³»ç»Ÿå”¯ä¸€å…¥å£
    
    åˆ›å»ºä¸»Flowå¹¶è¿è¡Œï¼ŒDispatcherNodeä¼šæ ¹æ®sharedé…ç½®è‡ªåŠ¨æµè½¬ã€‚
    
    Args:
        shared: åˆå§‹åŒ–åçš„sharedå­—å…¸
        concurrent_num: æœ€å¤§å¹¶å‘æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        wait_time: é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    """
    print_banner()
    print_config(shared, concurrent_num, max_retries, wait_time)
    
    # è®¾ç½®çº¿ç¨‹æ± ï¼ˆç”¨äºå¼‚æ­¥è°ƒç”¨åŒæ­¥LLMå‡½æ•°ï¼‰
    thread_pool_size = concurrent_num + 20
    executor = concurrent.futures.ThreadPoolExecutor(max_workers=thread_pool_size)
    loop = asyncio.get_running_loop()
    loop.set_default_executor(executor)
    print(f"[Main] çº¿ç¨‹æ± é…ç½®: max_workers={thread_pool_size}")
    
    start_time = time.time()
    print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\n")
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œä¸»Flow - DispatcherNodeä¼šæ ¹æ®é…ç½®è‡ªåŠ¨è°ƒåº¦
        main_flow = create_main_flow(
            concurrent_num=concurrent_num,
            max_retries=max_retries,
            wait_time=wait_time
        )
        await main_flow.run_async(shared)
        
        elapsed_time = time.time() - start_time
        print_results(shared, elapsed_time)
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {str(e)}")
        print(f"â±ï¸  è¿è¡Œæ—¶é—´: {elapsed_time:.2f} ç§’")
        import traceback
        traceback.print_exc()


def main():
    """
    ä¸»å‡½æ•°å…¥å£
    
    æ‰€æœ‰é…ç½®å‚æ•°ç›´æ¥åœ¨æ­¤å‡½æ•°ä¸­ä¿®æ”¹ã€‚
    ç³»ç»Ÿä¼šæ ¹æ®run_stagesé…ç½®è‡ªåŠ¨æ‰§è¡Œå¯¹åº”é˜¶æ®µã€‚
    """
    # =========================================================================
    # é…ç½®åŒºåŸŸ - ä¿®æ”¹ä»¥ä¸‹å‚æ•°è°ƒæ•´è¿è¡Œé…ç½®
    # =========================================================================
    
    # ----- æ•°æ®è·¯å¾„é…ç½® -----
    INPUT_DATA_PATH = "data/test_posts.json"
    OUTPUT_DATA_PATH = "data/test_enhanced_blogs.json"
    TOPICS_PATH = "data/topics.json"
    SENTIMENT_ATTRS_PATH = "data/sentiment_attributes.json"
    PUBLISHER_OBJS_PATH = "data/publisher_objects.json"
    
    # ----- æ‰§è¡Œé˜¶æ®µé…ç½® -----
    # è®¾ç½®éœ€è¦æ‰§è¡Œçš„é˜¶æ®µåˆ—è¡¨ï¼Œç›®å‰ä»…é˜¶æ®µ1å¯ç”¨
    # [1] = ä»…é˜¶æ®µ1, [1,2] = é˜¶æ®µ1å’Œ2, [1,2,3] = å…¨éƒ¨é˜¶æ®µ
    RUN_STAGES = [1]
    
    # ----- é˜¶æ®µ1é…ç½® -----
    ENHANCEMENT_MODE = "async"  # "async" | "batch_api"
    
    # ----- é˜¶æ®µ2é…ç½®ï¼ˆå¾…å®ç°ï¼‰ -----
    ANALYSIS_MODE = "workflow"  # "workflow" | "agent"
    TOOL_SOURCE = "local"       # "local" | "mcp"
    AGENT_MAX_ITERATIONS = 10
    
    # ----- é˜¶æ®µ3é…ç½®ï¼ˆå¾…å®ç°ï¼‰ -----
    REPORT_MODE = "template"    # "template" | "iterative"
    REPORT_MAX_ITERATIONS = 5
    REPORT_MIN_SCORE = 80
    
    # ----- Batch APIé…ç½® -----
    BATCH_SCRIPT_PATH = "batch/batch_run.py"
    
    # =========================================================================
    # åˆå§‹åŒ–sharedå­—å…¸å¹¶è¿è¡Œ
    # =========================================================================
    
    shared = init_shared(
        input_data_path=INPUT_DATA_PATH,
        output_data_path=OUTPUT_DATA_PATH,
        topics_path=TOPICS_PATH,
        sentiment_attributes_path=SENTIMENT_ATTRS_PATH,
        publisher_objects_path=PUBLISHER_OBJS_PATH,
        run_stages=RUN_STAGES,
        enhancement_mode=ENHANCEMENT_MODE,
        analysis_mode=ANALYSIS_MODE,
        tool_source=TOOL_SOURCE,
        agent_max_iterations=AGENT_MAX_ITERATIONS,
        report_mode=REPORT_MODE,
        report_max_iterations=REPORT_MAX_ITERATIONS,
        report_min_score=REPORT_MIN_SCORE,
        batch_script_path=BATCH_SCRIPT_PATH,
    )
    
    # è¿è¡Œç³»ç»Ÿ - DispatcherNodeä¼šæ ¹æ®é…ç½®è‡ªåŠ¨è°ƒåº¦
    # æ€§èƒ½å‚æ•°ä½¿ç”¨runå‡½æ•°çš„é»˜è®¤å€¼ï¼šconcurrent_num=60, max_retries=3, wait_time=8
    asyncio.run(run(shared=shared))


if __name__ == "__main__":
    main()
